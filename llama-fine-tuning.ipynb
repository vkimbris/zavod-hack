{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62e6f3d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "notebook_login() got an unexpected keyword argument 'token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notebook_login\n\u001b[0;32m---> 19\u001b[0m \u001b[43mnotebook_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhf_MTJIUWSdpigjjYugrNkboEFBcRrPkUqqJM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: notebook_login() got an unexpected keyword argument 'token'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers import get_linear_schedule_with_warmup, default_data_collator\n",
    "\n",
    "from datasets import load_dataset\n",
    "from peft import get_peft_model, TaskType, PeftType, LoraConfig\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bb4c542",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"meta-llama/Llama-2-13b-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "tokenizer.padding_token = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f015cafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/petrov/.cache/huggingface/datasets/csv/default-4d979e2ccfc28348/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3526e124c5bd4a09aee835a2742d09bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17caa3e72197453b88c416fa5a7bd8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/petrov/.cache/huggingface/datasets/csv/default-4d979e2ccfc28348/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a39421dfc1344d7bbd2d44eafa0f773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"csv\", data_files=[\"final.csv\"])\n",
    "\n",
    "dataset = dataset.rename_column(\"question\", \"input\")\n",
    "dataset = dataset.rename_column(\"answer\", \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710bd1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_MAX_LENGTH = 256\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    batch_size = len(examples[\"input\"])\n",
    "    \n",
    "    inputs = [x for x in examples[\"input\"]]\n",
    "    outputs = [y for y in examples[\"output\"]]\n",
    "    \n",
    "    inputs = tokenizer(inputs)\n",
    "    outputs = tokenizer(outputs)\n",
    "    \n",
    "    labels = []\n",
    "    for i in range(batch_size):\n",
    "        inputs[\"input_ids\"][i] = inputs[\"input_ids\"][i] + outputs[\"input_ids\"][i]\n",
    "        inputs[\"attention_mask\"][i] = inputs[\"attention_mask\"][i] + outputs[\"attention_mask\"][i]\n",
    "        \n",
    "        inputs[\"input_ids\"][i] = [tokenizer.padding_token] * (DEFAULT_MAX_LENGTH - len(inputs[\"input_ids\"][i])) + inputs[\"input_ids\"][i]\n",
    "        inputs[\"attention_mask\"][i] = [0] * (DEFAULT_MAX_LENGTH - len(inputs[\"attention_mask\"][i])) + inputs[\"attention_mask\"][i]\n",
    "    \n",
    "        labels.append([-100] * (DEFAULT_MAX_LENGTH - len(outputs[i])) + outputs[\"input_ids\"][i])\n",
    "    \n",
    "    inputs[\"labels\"] = labels\n",
    "    \n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b793addb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preprocessed_dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset[\"train\"].column_names)\n",
    "preprocessed_dataset = preprocessed_dataset.filter(lambda example: len(example[\"input_ids\"]) <= DEFAULT_MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88cf1ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = preprocessed_dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb847a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_BATCH_SIZE = 4\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              shuffle=True, \n",
    "                              collate_fn=default_data_collator, \n",
    "                              batch_size=DEFAULT_BATCH_SIZE, \n",
    "                              pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a98c944",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        r=8,\n",
    "        lora_alpha=32,\n",
    "        lora_dropout=0.05,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, device_map=DEVICE)\n",
    "\n",
    "peft_model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fdfb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 2e-4\n",
    "NUM_EPOCHS = 200\n",
    "\n",
    "optimizer = torch.optim.AdamW(peft_model.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataloader) * NUM_EPOCHS),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00471bc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bdbe6fee7c4dc3ba8b20b7d974dd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 304.1477355957031\n",
      "Epoch: 1, Loss: 165.57058715820312\n",
      "Epoch: 2, Loss: 102.98075103759766\n",
      "Epoch: 3, Loss: 62.22895431518555\n",
      "Epoch: 4, Loss: 36.84931945800781\n",
      "Epoch: 5, Loss: 22.163969039916992\n",
      "Epoch: 6, Loss: 14.491386413574219\n",
      "Epoch: 7, Loss: 7.249194622039795\n",
      "Epoch: 8, Loss: 4.066795349121094\n",
      "Epoch: 9, Loss: 3.220932960510254\n",
      "Epoch: 10, Loss: 2.840658664703369\n",
      "Epoch: 11, Loss: 3.0036818981170654\n",
      "Epoch: 12, Loss: 2.1213088035583496\n",
      "Epoch: 13, Loss: 4.486833095550537\n",
      "Epoch: 14, Loss: 16.343503952026367\n",
      "Epoch: 15, Loss: 5.068000793457031\n",
      "Epoch: 16, Loss: 2.1757116317749023\n",
      "Epoch: 17, Loss: 1.056728482246399\n",
      "Epoch: 18, Loss: 0.8358843922615051\n",
      "Epoch: 19, Loss: 0.7483575940132141\n",
      "Epoch: 20, Loss: 0.6977896690368652\n",
      "Epoch: 21, Loss: 0.6998245120048523\n",
      "Epoch: 22, Loss: 0.5825387239456177\n",
      "Epoch: 23, Loss: 0.5327775478363037\n",
      "Epoch: 24, Loss: 0.5002347230911255\n",
      "Epoch: 25, Loss: 0.4136040210723877\n",
      "Epoch: 26, Loss: 0.49295493960380554\n",
      "Epoch: 27, Loss: 0.39664068818092346\n",
      "Epoch: 28, Loss: 0.4297235608100891\n",
      "Epoch: 29, Loss: 0.4175715148448944\n",
      "Epoch: 30, Loss: 0.4025605320930481\n",
      "Epoch: 31, Loss: 8.745391845703125\n",
      "Epoch: 32, Loss: 49.38803482055664\n",
      "Epoch: 33, Loss: 8.567740440368652\n",
      "Epoch: 34, Loss: 1.9223607778549194\n",
      "Epoch: 35, Loss: 1.1717175245285034\n",
      "Epoch: 36, Loss: 0.9130035638809204\n",
      "Epoch: 37, Loss: 0.7140625715255737\n",
      "Epoch: 38, Loss: 0.6199213266372681\n",
      "Epoch: 39, Loss: 0.5989035367965698\n",
      "Epoch: 40, Loss: 0.4933554232120514\n",
      "Epoch: 41, Loss: 0.4436100721359253\n",
      "Epoch: 42, Loss: 0.5371467471122742\n",
      "Epoch: 43, Loss: 0.3982601761817932\n",
      "Epoch: 44, Loss: 0.37871652841567993\n",
      "Epoch: 45, Loss: 0.7624852061271667\n",
      "Epoch: 46, Loss: 0.38836410641670227\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> step, batch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(train_dataloader):                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 7 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>batch = {k: v.to(DEVICE) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> k, v <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> batch.items()}                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 8 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = peft_model(**batch)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss = outputs.loss                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>total_loss += loss.detach().float()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>loss.backward()                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/peft/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">peft_model.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">678</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 675 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>):                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 676 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>peft_config = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.active_peft_config                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 677 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(peft_config, PromptLearningConfig):                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 678 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.base_model(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 679 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>input_ids=input_ids,                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 680 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>attention_mask=attention_mask,                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 681 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>inputs_embeds=inputs_embeds,                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hooks.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new_forward</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>output = old_forward(*args, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output = old_forward(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> module._hf_hook.post_forward(module, output)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>module.forward = new_forward                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/transformers/models/gpt_neox/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt_neox</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">673</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 670 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">```\"\"\"</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 671 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>return_dict = return_dict <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> return_dict <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.config.use_return  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 672 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 673 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.gpt_neox(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 674 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>input_ids,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 675 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>attention_mask=attention_mask,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 676 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>position_ids=position_ids,                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hooks.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new_forward</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>output = old_forward(*args, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output = old_forward(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> module._hf_hook.post_forward(module, output)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>module.forward = new_forward                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/transformers/models/gpt_neox/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt_neox</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">564</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 561 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>head_mask[i],                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 562 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 563 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 564 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>outputs = layer(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 565 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>hidden_states,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 566 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>attention_mask=attention_mask,                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 567 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>position_ids=position_ids,                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hooks.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new_forward</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>output = old_forward(*args, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output = old_forward(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> module._hf_hook.post_forward(module, output)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>module.forward = new_forward                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/transformers/models/gpt_neox/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt_neox</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">346</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 343 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.use_parallel_residual:                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 344 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># pseudocode:</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 345 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># x = x + attn(ln1(x)) + mlp(ln2(x))</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 346 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>mlp_output = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.mlp(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.post_attention_layernorm(hidden_states))           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 347 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>hidden_states = mlp_output + attn_output + hidden_states                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 348 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 349 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># pseudocode:</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">hooks.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">new_forward</span>         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>output = old_forward(*args, **kwargs)                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">164 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>165 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output = old_forward(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> module._hf_hook.post_forward(module, output)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>module.forward = new_forward                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/transformers/models/gpt_neox/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_gpt_neox</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">307</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 304 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 305 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, hidden_states):                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 306 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dense_h_to_4h(hidden_states)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 307 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.act(hidden_states)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 308 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>hidden_states = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dense_4h_to_h(hidden_states)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 309 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> hidden_states                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 310 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1194</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1191 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># this function, and just call forward.</span>                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1192 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">o</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1193 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1194 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>, **kwargs)                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1195 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1196 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1197 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks:                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/netcrk/cp31012/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">activations.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">78</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 75 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span> * <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0.5</span> * (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1.0</span> + torch.erf(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span> / math.sqrt(<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2.0</span>)))                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 76 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 77 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>: Tensor) -&gt; Tensor:                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 78 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.act(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">input</span>)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 79 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 80 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 81 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">FastGELUActivation</span>(nn.Module):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyboardInterrupt</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m8\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m step, batch \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(train_dataloader):                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 7 \u001b[0m\u001b[2m│   │   \u001b[0mbatch = {k: v.to(DEVICE) \u001b[94mfor\u001b[0m k, v \u001b[95min\u001b[0m batch.items()}                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 8 \u001b[2m│   │   \u001b[0moutputs = peft_model(**batch)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   │   \u001b[0mloss = outputs.loss                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m\u001b[2m│   │   \u001b[0mtotal_loss += loss.detach().float()                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m│   │   \u001b[0mloss.backward()                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/peft/\u001b[0m\u001b[1;33mpeft_model.py\u001b[0m:\u001b[94m678\u001b[0m in \u001b[92mforward\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 675 \u001b[0m\u001b[2m│   \u001b[0m):                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 676 \u001b[0m\u001b[2m│   │   \u001b[0mpeft_config = \u001b[96mself\u001b[0m.active_peft_config                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 677 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m \u001b[96misinstance\u001b[0m(peft_config, PromptLearningConfig):                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 678 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.base_model(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 679 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minput_ids=input_ids,                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 680 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mattention_mask=attention_mask,                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 681 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs_embeds=inputs_embeds,                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33mhooks.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mnew_forward\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m module._hf_hook.post_forward(module, output)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   \u001b[0mmodule.forward = new_forward                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/transformers/models/gpt_neox/\u001b[0m\u001b[1;33mmodeling_gpt_neox\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m673\u001b[0m in \u001b[92mforward\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 670 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m```\"\"\"\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 671 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.config.use_return  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 672 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 673 \u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.gpt_neox(                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 674 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids,                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 675 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 676 \u001b[0m\u001b[2m│   │   │   \u001b[0mposition_ids=position_ids,                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33mhooks.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mnew_forward\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m module._hf_hook.post_forward(module, output)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   \u001b[0mmodule.forward = new_forward                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/transformers/models/gpt_neox/\u001b[0m\u001b[1;33mmodeling_gpt_neox\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m564\u001b[0m in \u001b[92mforward\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 561 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhead_mask[i],                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 562 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 563 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 564 \u001b[2m│   │   │   │   \u001b[0moutputs = layer(                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 565 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mhidden_states,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 566 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mattention_mask=attention_mask,                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 567 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mposition_ids=position_ids,                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33mhooks.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mnew_forward\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m module._hf_hook.post_forward(module, output)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   \u001b[0mmodule.forward = new_forward                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/transformers/models/gpt_neox/\u001b[0m\u001b[1;33mmodeling_gpt_neox\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m346\u001b[0m in \u001b[92mforward\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 343 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.use_parallel_residual:                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 344 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# pseudocode:\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 345 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# x = x + attn(ln1(x)) + mlp(ln2(x))\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 346 \u001b[2m│   │   │   \u001b[0mmlp_output = \u001b[96mself\u001b[0m.mlp(\u001b[96mself\u001b[0m.post_attention_layernorm(hidden_states))           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 347 \u001b[0m\u001b[2m│   │   │   \u001b[0mhidden_states = mlp_output + attn_output + hidden_states                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 348 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 349 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# pseudocode:\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33mhooks.py\u001b[0m:\u001b[94m165\u001b[0m in \u001b[92mnew_forward\u001b[0m         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m165 \u001b[2m│   │   │   \u001b[0moutput = old_forward(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m module._hf_hook.post_forward(module, output)                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   \u001b[0mmodule.forward = new_forward                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/transformers/models/gpt_neox/\u001b[0m\u001b[1;33mmodeling_gpt_neox\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m307\u001b[0m in \u001b[92mforward\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 304 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 305 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, hidden_states):                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 306 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states = \u001b[96mself\u001b[0m.dense_h_to_4h(hidden_states)                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 307 \u001b[2m│   │   \u001b[0mhidden_states = \u001b[96mself\u001b[0m.act(hidden_states)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 308 \u001b[0m\u001b[2m│   │   \u001b[0mhidden_states = \u001b[96mself\u001b[0m.dense_4h_to_h(hidden_states)                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 309 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m hidden_states                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 310 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1194\u001b[0m in \u001b[92m_call_impl\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1191 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# this function, and just call forward.\u001b[0m                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1192 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_pre_hooks \u001b[95mo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1193 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1194 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*\u001b[96minput\u001b[0m, **kwargs)                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1195 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1196 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1197 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m _global_backward_hooks:                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/netcrk/cp31012/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mactivations.py\u001b[0m:\u001b[94m78\u001b[0m in \u001b[92mforward\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 75 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96minput\u001b[0m * \u001b[94m0.5\u001b[0m * (\u001b[94m1.0\u001b[0m + torch.erf(\u001b[96minput\u001b[0m / math.sqrt(\u001b[94m2.0\u001b[0m)))                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 78 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.act(\u001b[96minput\u001b[0m)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 79 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 80 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 81 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mFastGELUActivation\u001b[0m(nn.Module):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyboardInterrupt\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = []\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    peft_model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
    "        outputs = peft_model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.detach().float()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    losses.append(total_loss.item())\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accb806c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at the last epoch:  0.38836410641670227\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(losses)\n",
    "plt.show()\n",
    "\n",
    "print(\"Loss at the last epoch: \", losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6cca384",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model.save_pretrained(\"adapters/pythia-lora-o2-augmented-fails-qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00b597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
